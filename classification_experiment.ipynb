{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from utility import train_test_split\n",
    "from numpy import unique\n",
    "from utility import load_data, batch_training_generator\n",
    "from torch_utility import accuracy, fully_connected, Flatten\n",
    "from sequential import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = os.getcwd() + '/grey_images_32' \n",
    "X_raw, labels = load_data(image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "length, width = X_raw[0].shape\n",
    "X = torch.Tensor(X_raw).type(torch.float32)\n",
    "X = X.view(-1, 1, length, width)\n",
    "X /= 255\n",
    "unique_y = unique(labels)\n",
    "y_dim = len(unique_y)\n",
    "num_unique_labels = len(unique_y)\n",
    "mapping = {label: i for i, label in enumerate(unique_y)}\n",
    "numeric_labels = torch.Tensor([mapping[label] for label in labels]).type(torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, numeric_labels, test_size=0.1,\n",
    "                                                    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (layers): ModuleList(\n",
       "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Flatten()\n",
       "    (4): Linear(in_features=1176, out_features=1176, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=1176, out_features=29, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = len(X_train)\n",
    "\n",
    "# 32 X 32 X 1\n",
    "layers = [nn.Conv2d(1, 6, 5), # 28 X 28 X 32\n",
    "          nn.ReLU(),\n",
    "          nn.MaxPool2d(2, 2), # 14 X 14 X 32\n",
    "          Flatten(),\n",
    "          nn.Linear(14 * 14 * 6, 14 * 14 * 6),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(14 * 14 * 6, y_dim)\n",
    "         ]\n",
    "model = Sequential(*layers)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.2058014557260321 0.8569731800766284 0.8489655172413794\n",
      "1 0.27443375160510186 0.9478544061302682 0.9394252873563218\n",
      "2 0.13408954219448788 0.9686973180076628 0.9605747126436781\n",
      "3 0.08418097798585222 0.9752234993614304 0.9691954022988506\n",
      "4 0.06827845129441812 0.9742784163473819 0.9681609195402299\n",
      "5 0.04558094807350699 0.987816091954023 0.9845977011494252\n",
      "6 0.0420082114452498 0.9934610472541507 0.9916091954022989\n",
      "7 0.0377512392063295 0.991698595146871 0.9881609195402299\n",
      "8 0.03542796586714303 0.9955938697318008 0.9939080459770115\n",
      "9 0.026145958922029422 0.9774457215836526 0.9725287356321839\n"
     ]
    }
   ],
   "source": [
    "def entropy_train(model)\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "op = torch.optim.Adam(model.parameters(), lr=.001)\n",
    "loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
    "for epoch_num in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    training = batch_training_generator(X_train, y_train, batch_size,\n",
    "                                        shuffle=True)\n",
    "    for x_set, y_set in training:\n",
    "        op.zero_grad()\n",
    "        output = model(x_set)\n",
    "        loss = loss_fn(output, y_set)\n",
    "        loss /= N\n",
    "        epoch_loss += float(loss)\n",
    "        loss.backward()\n",
    "        op.step()\n",
    "    print(epoch_num, epoch_loss, accuracy(model, X_train, y_train), accuracy(model, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
